# 初探大模型
AI自从1950开始被提出，到目前主要经历了四个发展阶段。AI研究主要有两个学派，一是链接主义还有一个是符号主义。
### 起源与发展
1. 解码注意力机制（Attention）
解码注意力的主要目的是在处理信息的时候能够聚焦于特定部分的技术。注意力机制通过计算不同信息片段的重要性，并据此分配不同的处理权重。
注意力机制实现步骤：
   - 确定信息片段 : 首先，模型需要识别出文本中的各个信息片段。
   - 计算权重 : 然后，模型会计算每个片段对于当前任务的重要性，这个过程称为“打分”。
   - 分配注意力: 根据打分结果，模型会给每个片段分配不同的注意力权重，重要的片段会获得更多的关注。
   - 整合信息: 最后，模型会综合考虑所有片段的信息，生成最终的输出。

2. Transformer - 变革里程碑
transformer是基于注意力机制的深度学习模型，并行计算能力强，长距离依赖关系捕捉能力强，训练速度快。
transformer的实现步骤:
    - 编码器：编码器将输入序列转换为一个向量序列。
    - 解码器：解码器将编码生成的向量序列转换成输出序列。
    - 注意力机制： 注意力机制可以帮助模型关注输入序列中与当前词相关的部分。
    - 多头注意力机制：多头注意力机制可以帮助模型c
3. GPT 与 Bert
### 大语言模型家族

<!--stackedit_data:
eyJoaXN0b3J5IjpbMTIzODYyODUzNSwtMTU4ODcwNTU0MCwtNT
k4NjE3MzI4LC0xMzQ5NTE2OTU4LC0xMTkzOTAwMTgzLC05NzU0
ODI3NTMsLTkwMzk5NTM5Myw4NDY2NTMzNTFdfQ==
-->